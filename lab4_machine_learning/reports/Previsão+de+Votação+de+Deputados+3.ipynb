{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão de Votação de Deputados\n",
    "\n",
    "## A tarefa\n",
    "\n",
    "Nesta atividade construiremos modelos preditivos de regressão em scikit learn para a predição dos votos de deputados federais considerando as últimas eleições. As atividades esperadas para essa etapa são descritas a seguir:\n",
    "\n",
    "1. Baixe os dados [aqui](https://canvas.instructure.com/courses/1389733/files/69523670/download?verifier=A5EPvssqIQCjlxpWQyesLFer1VDTlRyTAAXR2iyi&wrap=1).\n",
    "2. Considere o pipeline mostrado nesse [link](https://www.kaggle.com/apapiu/regularized-linear-models) para construir seus modelos de regressão. Isso implica, dentre outras coisas:\n",
    "    1. Analisar as distribuições das variáveis para ver se estão enviesadas e precisam de correção; tratamento de valores ausentes, variáveis categóricas e normalização, quando for o caso.\n",
    "    2. Construir modelos de regressão com (ridge e lasso) e sem regularização.\n",
    "    3. Considerar também modelos de regressão não paramétrica como K-NN.\n",
    "    4. Considerar outros modelos ainda não vistos em sala de sua escolha (e.g. SVR, Regression Trees e Random Florests).\n",
    "    5. Tunar os hiperâmetros para cada caso e retornar os rmses de validação cruzada para todos os modelos avaliados.\n",
    "    6. Plotar os resíduos versus predições e analisar se esses plots representam bons indícios da adequabilidade dos modelos a esse problema.\n",
    "3. Alguns dias antes da entrega final serão liberados os dados de teste referentes à 2014 para validação final dos seus melhores modelos.\n",
    "    1. Dica: Uma coisa que você pode fazer é usar os dados de 2006 como treino e os de 2010 como validação. Uma vez encontrados os melhores modelos para 2010 junte 2006+2010, retreine, e aplique o modelo aos dados de 2014 que serão liberados.\n",
    "4. Responder:\n",
    "    1. Dentre os modelos avaliados, qual foi o que deu o melhor resultado nos dados de 2014 em termos de RMSE? Justifique bem sua resposta.\n",
    "A entrega deve ser um notebook Jupyter com código python e texto explicativo quando necessário. Crie um repositório na sua conta do github e envie o link do html do notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre os dados\n",
    "\n",
    "Vamos explorar dados sobre as votações que candidatos à Câmara Federal de Deputados receberam nos anos de 2006 e 2010. Esses dados foram extraídos do [TSE](http://www.tse.jus.br/hotSites/pesquisas-eleitorais/index.html), pré-processados e contemplam informações sobre aproximadamente 7.300 candidatos. A descrição de cada atributo é dada mais abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Variável                                   | Tipo | Descrição |\n",
    "|-------------------------------------------|------|-----------|\n",
    "|\"sequencial_candidato\"| (character) | id do candidato|\n",
    "|\"nome\"| (character) | |\n",
    "|\"uf\" | (character) | |\n",
    "|\"partido\" | (character)| |\n",
    "|\"quantidade_doacoes\"| (integer)| |\n",
    "|\"quantidade_doadores\"| (integer) | número de doadores diferentes|\n",
    "|\"total_receita\" | (double) | soma em R\\$ das doações |\n",
    "|\"media_receita\" | (double) | média das doações |\n",
    "|\"recursos_de_outros_candidatos/comites\" | (double) | quantia em R\\$ das doações provenientes de outros candidatos ou comite partidário |\n",
    "|\"recursos_de_pessoas_fisicas\" | (double) | quantia em R\\$ das doações provenientes de outros CPFs |\n",
    "|\"recursos_de_pessoas_juridicas\" | (double) | quantia em R\\$ das doações provenientes de outros CNPJ |\n",
    "|\"recursos_proprios\" | (double) | quantia em R\\$ das doações provenientes do próprio candidato |\n",
    "|\"recursos_de_partido_politico\" | (double) | quantia em R\\$ das doações provenientes do partido político do candidato |\n",
    "|**\"votos\"** | (integer) | **variável alvo**. Se refere ao número de votos na campanha de 2006 e 2010 |\n",
    "|\"quantidade_despesas\" | (integer) | |\n",
    "|\"quantidade_fornecedores\" | (integer) | número de fornecedores/despesas diferentes |\n",
    "|\"total_despesa\" | (double) | soma em R$ das despesas de campanha |\n",
    "|\"media_despesa\" | (double) | média das despesas de campanha |\n",
    "|\"cargo\" |(character) | |\n",
    "|\"Sexo\": | (character) | |\n",
    "|\"grau\": | (character) | grau de instrução do candidato |\n",
    "|\"estado_civil\" | (character) |\n",
    "|\"ocupacao\" | (character) | ocupação do candidato |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import imblearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para regressão linear sem regularização\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Para regressão linear com regularização\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, Lasso, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# não paramétrica K-NN\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando\n",
    "eleicoes_train = pd.read_csv('../data/train.csv')\n",
    "eleicoes_test = pd.read_csv('../data/test.csv')\n",
    "directions = pd.read_csv('../data/directions.csv')\n",
    "regions = pd.read_csv('../data/regions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "direction2=[]\n",
    "region2=[]\n",
    "for index,row in eleicoes_train.iterrows():\n",
    "    direction2.append(directions[row['partido']][0])  \n",
    "    region2.append(regions[row['uf']][0])    \n",
    "eleicoes_train['direction'] = direction2  \n",
    "eleicoes_train['region'] = region2\n",
    "direction2=[]\n",
    "region2=[]\n",
    "for index,row in eleicoes_test.iterrows():\n",
    "    direction2.append(directions[row['partido']][0])\n",
    "    region2.append(regions[row['uf']][0])    \n",
    "eleicoes_test['direction'] = direction2\n",
    "eleicoes_test['region'] = region2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ano</th>\n",
       "      <th>sequencial_candidato</th>\n",
       "      <th>nome</th>\n",
       "      <th>uf</th>\n",
       "      <th>partido</th>\n",
       "      <th>quantidade_doacoes</th>\n",
       "      <th>quantidade_doadores</th>\n",
       "      <th>total_receita</th>\n",
       "      <th>media_receita</th>\n",
       "      <th>recursos_de_outros_candidatos.comites</th>\n",
       "      <th>...</th>\n",
       "      <th>quantidade_fornecedores</th>\n",
       "      <th>total_despesa</th>\n",
       "      <th>media_despesa</th>\n",
       "      <th>cargo</th>\n",
       "      <th>sexo</th>\n",
       "      <th>grau</th>\n",
       "      <th>estado_civil</th>\n",
       "      <th>ocupacao</th>\n",
       "      <th>direction</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>10000000135</td>\n",
       "      <td>EMERSON DA SILVA SANTOS</td>\n",
       "      <td>AC</td>\n",
       "      <td>PSOL</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1580.00</td>\n",
       "      <td>526.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1580.00</td>\n",
       "      <td>526.67</td>\n",
       "      <td>DEPUTADO FEDERAL</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>ENSINO MÉDIO COMPLETO</td>\n",
       "      <td>SOLTEIRO(A)</td>\n",
       "      <td>CORRETOR DE IMÓVEIS, SEGUROS, TÍTULOS E VALORES</td>\n",
       "      <td>L</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>10000000142</td>\n",
       "      <td>GERALDO SILVA DOS SANTOS</td>\n",
       "      <td>AC</td>\n",
       "      <td>PSOL</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3180.00</td>\n",
       "      <td>636.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3130.02</td>\n",
       "      <td>521.67</td>\n",
       "      <td>DEPUTADO FEDERAL</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>SUPERIOR COMPLETO</td>\n",
       "      <td>SOLTEIRO(A)</td>\n",
       "      <td>VIGILANTE</td>\n",
       "      <td>L</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>10000000158</td>\n",
       "      <td>CARLOS CESAR CORREIA DE MESSIAS</td>\n",
       "      <td>AC</td>\n",
       "      <td>PSB</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>336793.13</td>\n",
       "      <td>8419.83</td>\n",
       "      <td>1923.07</td>\n",
       "      <td>...</td>\n",
       "      <td>139</td>\n",
       "      <td>326869.78</td>\n",
       "      <td>2254.27</td>\n",
       "      <td>DEPUTADO FEDERAL</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>ENSINO FUNDAMENTAL INCOMPLETO</td>\n",
       "      <td>CASADO(A)</td>\n",
       "      <td>OUTROS</td>\n",
       "      <td>L</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>10000000161</td>\n",
       "      <td>IDESIO LUIS FRANKE</td>\n",
       "      <td>AC</td>\n",
       "      <td>PT</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>156719.32</td>\n",
       "      <td>5404.11</td>\n",
       "      <td>39122.32</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>241016.07</td>\n",
       "      <td>1772.18</td>\n",
       "      <td>DEPUTADO FEDERAL</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>SUPERIOR COMPLETO</td>\n",
       "      <td>CASADO(A)</td>\n",
       "      <td>AGRÔNOMO</td>\n",
       "      <td>L</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>10000000163</td>\n",
       "      <td>LEONARDO CUNHA DE BRITO</td>\n",
       "      <td>AC</td>\n",
       "      <td>PT</td>\n",
       "      <td>160</td>\n",
       "      <td>146</td>\n",
       "      <td>737073.00</td>\n",
       "      <td>4606.71</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>...</td>\n",
       "      <td>354</td>\n",
       "      <td>567401.15</td>\n",
       "      <td>1095.37</td>\n",
       "      <td>DEPUTADO FEDERAL</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>SUPERIOR COMPLETO</td>\n",
       "      <td>CASADO(A)</td>\n",
       "      <td>ADVOGADO</td>\n",
       "      <td>L</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ano  sequencial_candidato                             nome  uf partido  \\\n",
       "0  2014           10000000135          EMERSON DA SILVA SANTOS  AC    PSOL   \n",
       "1  2014           10000000142         GERALDO SILVA DOS SANTOS  AC    PSOL   \n",
       "2  2014           10000000158  CARLOS CESAR CORREIA DE MESSIAS  AC     PSB   \n",
       "3  2014           10000000161               IDESIO LUIS FRANKE  AC      PT   \n",
       "4  2014           10000000163          LEONARDO CUNHA DE BRITO  AC      PT   \n",
       "\n",
       "   quantidade_doacoes  quantidade_doadores  total_receita  media_receita  \\\n",
       "0                   3                    3        1580.00         526.67   \n",
       "1                   5                    5        3180.00         636.00   \n",
       "2                  40                   38      336793.13        8419.83   \n",
       "3                  29                   29      156719.32        5404.11   \n",
       "4                 160                  146      737073.00        4606.71   \n",
       "\n",
       "   recursos_de_outros_candidatos.comites  ...    quantidade_fornecedores  \\\n",
       "0                                   0.00  ...                          3   \n",
       "1                                   0.00  ...                          5   \n",
       "2                                1923.07  ...                        139   \n",
       "3                               39122.32  ...                        121   \n",
       "4                               10000.00  ...                        354   \n",
       "\n",
       "   total_despesa  media_despesa             cargo       sexo  \\\n",
       "0        1580.00         526.67  DEPUTADO FEDERAL  MASCULINO   \n",
       "1        3130.02         521.67  DEPUTADO FEDERAL  MASCULINO   \n",
       "2      326869.78        2254.27  DEPUTADO FEDERAL  MASCULINO   \n",
       "3      241016.07        1772.18  DEPUTADO FEDERAL  MASCULINO   \n",
       "4      567401.15        1095.37  DEPUTADO FEDERAL  MASCULINO   \n",
       "\n",
       "                            grau  estado_civil  \\\n",
       "0          ENSINO MÉDIO COMPLETO   SOLTEIRO(A)   \n",
       "1              SUPERIOR COMPLETO   SOLTEIRO(A)   \n",
       "2  ENSINO FUNDAMENTAL INCOMPLETO     CASADO(A)   \n",
       "3              SUPERIOR COMPLETO     CASADO(A)   \n",
       "4              SUPERIOR COMPLETO     CASADO(A)   \n",
       "\n",
       "                                          ocupacao direction region  \n",
       "0  CORRETOR DE IMÓVEIS, SEGUROS, TÍTULOS E VALORES         L     NO  \n",
       "1                                        VIGILANTE         L     NO  \n",
       "2                                           OUTROS         L     NO  \n",
       "3                                         AGRÔNOMO         L     NO  \n",
       "4                                         ADVOGADO         L     NO  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eleicoes_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#eleicoes = pd.concat((eleicoes_train,eleicoes_test),sort='false')\n",
    "eleicoes = eleicoes_train\n",
    "eleicoes = eleicoes.reindex(columns=eleicoes.columns)\n",
    "eleicoes_test = eleicoes_test.reindex(columns=eleicoes_test.columns)\n",
    "\n",
    "\n",
    "eleicoes, eleicoes_val = train_test_split(eleicoes, test_size=0.3, random_state=0)\n",
    "\n",
    "eleicoes, eleicoes_val2 = train_test_split(eleicoes, test_size=0.427, random_state=0)\n",
    "\n",
    "eleicoes = eleicoes.fillna(eleicoes.mean())\n",
    "eleicoes_val = eleicoes_val.fillna(eleicoes_val.mean())\n",
    "eleicoes_val2 = eleicoes_val2.fillna(eleicoes_val2.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleicoes_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleicoes_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleicoes_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(style='ticks'):\n",
    "    g = sns.factorplot(\"situacao\", \"media_despesa\", \"ano\", data=eleicoes, kind=\"box\")\n",
    "    g.set_axis_labels(\"Situação\", \"Despesas médias\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "eleitos = eleicoes.loc[:,[\n",
    "       'ano', 'situacao'\n",
    "    ]]\n",
    "\n",
    "eleitos_test = eleicoes_test.loc[:,[\n",
    "       'ano', 'situacao'\n",
    "    ]]\n",
    "\n",
    "eleitos_val = eleicoes_val.loc[:,[\n",
    "       'ano', 'situacao'\n",
    "    ]]\n",
    "\n",
    "eleitos_val2 = eleicoes_val2.loc[:,[\n",
    "       'ano', 'situacao'\n",
    "    ]]\n",
    "\n",
    "\n",
    "#eleitos = eleitos.reindex(columns=eleitos.columns)\n",
    "#eleitos_test = eleitos_test.reindex(columns=eleitos_test.columns)\n",
    "#eleitos_val = eleitos_val.reindex(columns=eleitos_val.columns)\n",
    "#eleitos_val2 = eleitos_val2.reindex(columns=eleitos_val2.columns)\n",
    "\n",
    "eleitos = eleitos.fillna(eleitos.mean())\n",
    "eleitos_test = eleitos_test.fillna(eleitos_test.mean())\n",
    "eleitos_val = eleitos_val.fillna(eleitos_val.mean())\n",
    "eleitos_val2 = eleitos_val2.fillna(eleitos_val2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "eleicoes = eleicoes.loc[:,[\n",
    "       'uf', 'ano', 'situacao', 'sequencial_candidato', 'nome', 'partido', 'quantidade_doacoes', 'total_receita', 'quantidade_doadores', \n",
    "       'recursos_de_outros_candidatos.comites', 'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "       'recursos_proprios', 'recursos_de_partido_politico', 'quantidade_despesas', 'quantidade_fornecedores',\n",
    "       'total_despesa', 'cargo', 'sexo', 'grau_instrucao',\n",
    "       'estado_civil', 'ocupacao', 'direction', 'region'\n",
    "    ]]\n",
    "eleicoes_test = eleicoes_test.loc[:,[\n",
    "       'uf', 'ano', 'situacao', 'sequencial_candidato', 'nome', 'partido', 'quantidade_doacoes', 'total_receita', 'quantidade_doadores', \n",
    "       'recursos_de_outros_candidatos.comites', 'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "       'recursos_proprios', 'recursos_de_partido_politico', 'quantidade_despesas', 'quantidade_fornecedores',\n",
    "       'total_despesa', 'cargo', 'sexo', 'grau_instrucao',\n",
    "       'estado_civil', 'ocupacao', 'direction', 'region'\n",
    "    ]]\n",
    "eleicoes_val = eleicoes_val.loc[:,[\n",
    "       'uf', 'ano', 'situacao', 'sequencial_candidato', 'nome', 'partido', 'quantidade_doacoes', 'total_receita', 'quantidade_doadores', \n",
    "       'recursos_de_outros_candidatos.comites', 'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "       'recursos_proprios', 'recursos_de_partido_politico', 'quantidade_despesas', 'quantidade_fornecedores',\n",
    "       'total_despesa', 'cargo', 'sexo', 'grau_instrucao',\n",
    "       'estado_civil', 'ocupacao', 'direction', 'region'\n",
    "    ]]\n",
    "eleicoes_val2 = eleicoes_val2.loc[:,[\n",
    "       'uf', 'ano', 'situacao', 'sequencial_candidato', 'nome', 'partido', 'quantidade_doacoes', 'total_receita', 'quantidade_doadores', \n",
    "       'recursos_de_outros_candidatos.comites', 'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "       'recursos_proprios', 'recursos_de_partido_politico', 'quantidade_despesas', 'quantidade_fornecedores',\n",
    "       'total_despesa', 'cargo', 'sexo', 'grau_instrucao',\n",
    "       'estado_civil', 'ocupacao', 'direction', 'region'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleicoes = pd.get_dummies(eleicoes, \n",
    "                          prefix=['region', 'direction', 'ocupacao','situacao'], \n",
    "                          columns=['region', 'direction', 'ocupacao','situacao'])\n",
    "eleicoes_test = pd.get_dummies(eleicoes_test, \n",
    "                          prefix=['region', 'direction', 'ocupacao','situacao'], \n",
    "                          columns=['region', 'direction', 'ocupacao','situacao'])\n",
    "eleicoes_val = pd.get_dummies(eleicoes_val, \n",
    "                          prefix=['region', 'direction', 'ocupacao','situacao'], \n",
    "                          columns=['region', 'direction', 'ocupacao','situacao'])\n",
    "eleicoes_val2 = pd.get_dummies(eleicoes_val2, \n",
    "                          prefix=['region', 'direction', 'ocupacao','situacao'], \n",
    "                          columns=['region', 'direction', 'ocupacao','situacao'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "with sns.axes_style('white'):\n",
    "    g = sns.factorplot(\"situacao\", data=eleitos, aspect=2,\n",
    "                       kind=\"count\", color='steelblue')\n",
    "    g.set_xticklabels(step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pré-Processamento inicial para evitar número de colunas diferente entre as bases de tesate e treino\n",
    "eleicoes = pd.get_dummies(eleicoes, \n",
    "                          prefix=['uf', 'partido', 'cargo', 'sexo', 'grau_instrucao', 'estado_civil', 'ocupacao'], \n",
    "                          columns=['uf', 'partido', 'cargo', 'sexo', 'grau_instrucao', 'estado_civil', 'ocupacao'])\n",
    "\n",
    "#eleicoes['recursos'] = (eleicoes.test_one + df.test_two)\n",
    "\n",
    "#features = eleicoes.loc[eleicoes['ano'] != 2014].drop(columns=['votos'])\n",
    "features = eleicoes.loc[eleicoes['ano'] != 2014]\n",
    "#target = eleicoes.loc[eleicoes['ano'] != 2014].votos\n",
    "target = eleitos.loc[eleitos['ano'] != 2014].drop(columns=['ano'])\n",
    "\n",
    "#features = features.loc[:,[\n",
    "#       'uf', 'quantidade_doacoes', 'total_receita', 'partido', 'quantidade_doadores', \n",
    "#       'recursos_de_outros_candidatos/comites',\n",
    "#       'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "#       'recursos_proprios', 'quantidade_despesas', 'quantidade_fornecedores',\n",
    "#       'total_despesa', 'cargo', 'sexo', 'grau',\n",
    "#       'estado_civil', 'ocupacao'\n",
    "#    ]]\n",
    "\n",
    "x_test_final = eleicoes.loc[eleicoes['ano'] == 2014]\n",
    "y_test_final = eleitos.loc[eleitos['ano'] == 2014].drop(columns=['ano'])\n",
    "\n",
    "#x_teste_final = x_teste_final.loc[:,[\n",
    "#       'uf', 'quantidade_doacoes', 'total_receita', 'partido', 'quantidade_doadores', \n",
    "#       'recursos_de_outros_candidatos/comites',\n",
    "#       'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "#       'recursos_proprios', 'quantidade_despesas', 'quantidade_fornecedores',\n",
    "#       'total_despesa', 'cargo', 'sexo', 'grau',\n",
    "#       'estado_civil', 'ocupacao'\n",
    "#    ]]\n",
    "\n",
    "#treino 75% e validação 25%\n",
    "x_treino, x_validacao, y_treino, y_validacao = train_test_split(features, target, random_state = 8)\n",
    "\n",
    "x_treino_final = features\n",
    "y_treino_final = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleicoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def plot_2d_space(X, y, label='Classes'):   \n",
    "#    colors = ['#770000', '#1FC7E4']\n",
    "#    markers = ['o', 's']\n",
    "#    for l, c, m in zip(np.unique(y), colors, markers):\n",
    "#        plt.scatter(\n",
    "#            X[y==l, 0],\n",
    "#            X[y==l, 1],\n",
    "#            c=c, label=l, marker=m, alpha =0.1\n",
    "#        )\n",
    "#    plt.title(label)\n",
    "#    plt.legend(loc='upper right')\n",
    "#    plt.show()\n",
    "\n",
    "def plot_2d_space(X, y, label='Classes'):   \n",
    "    colors = ['#1F77B4', '#FF7F0E']\n",
    "    markers = ['o', 's']\n",
    "    for l, c, m in zip(np.unique(y), colors, markers):\n",
    "        plt.scatter(\n",
    "            X[y==l, 0],\n",
    "            X[y==l, 1],\n",
    "            c=c, label=l, marker=m, alpha =0.1\n",
    "        )\n",
    "    plt.title(label)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "def plot_2d_space_logy(X, y, label='Classes'):   \n",
    "    colors = ['purple', 'yellow']\n",
    "    markers = ['o', 's']\n",
    "    for l, c, m in zip(np.unique(y), colors, markers):\n",
    "        plt.scatter(\n",
    "            X[y==l, 0],\n",
    "            np.log1p(X[y==l, 1]),\n",
    "            c=c, label=l, marker=m, alpha =0.5\n",
    "        )\n",
    "    plt.title(label)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "#non_cols = ['sequencial_candidato', 'nome', 'uf', 'partido', 'cargo', 'sexo', 'grau_instrucao', 'estado_civil', 'ocupacao'] \n",
    "# Takes all 47 other columns\n",
    "#cols = list(set(eleicoes.columns) - set(non_cols))\n",
    "\n",
    "#pca = PCA(n_components=2)\n",
    "#X = pca.fit_transform(eleicoes.loc[:,cols])\n",
    "\n",
    "#plot_2d_space(X, pd.get_dummies(eleitos.situacao).nao_eleito , 'Imbalanced dataset (2 PCA components)')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "non_cols = ['sequencial_candidato', 'nome'] \n",
    "\n",
    "\n",
    "cols = ['total_receita', 'quantidade_doadores', 'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "       'recursos_proprios']\n",
    "\n",
    "colors = ['#770000', '#1FC7E4']\n",
    "markers = ['o', 's']\n",
    "\n",
    "c = pd.get_dummies(eleitos.situacao).nao_eleito\n",
    "l = np.unique(c)\n",
    "\n",
    "plt.scatter(\n",
    "    eleicoes[\"total_receita\"],\n",
    "    np.log1p(eleicoes[\"quantidade_doadores\"]),\n",
    "    c=c, alpha =0.5\n",
    ")\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "#cols = list(set(eleicoes.columns) - set(non_cols))\n",
    "\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "X_rus, y_rus, id_rus = rus.fit_sample(eleicoes.loc[:,cols], pd.get_dummies(eleitos.situacao).nao_eleito)\n",
    "\n",
    "print('Removed indexes:', id_rus)\n",
    "\n",
    "#plot_2d_space(X_rus, y_rus, 'Random under-sampling')\n",
    "\n",
    "#plt.hist(y_rus, density =1)\n",
    "\n",
    "df = pd.DataFrame(X_rus)\n",
    "df['situacao'] = y_rus\n",
    "df.situacao.value_counts().plot(kind='bar', title='Under 1 Count (situacao)');\n",
    "\n",
    "\n",
    "\n",
    "#plt.hist(y_rus, 3, facecolor='green', alpha=0.75)\n",
    "\n",
    "#plt.xlabel('Smarts')\n",
    "#plt.ylabel('Probability')\n",
    "#plt.title(r'$\\mathrm{Histogram\\ of\\ IQ:}\\ \\mu=100,\\ \\sigma=15$')\n",
    "#plt.axis([0,1,0,1100])\n",
    "#plt.grid(True)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#eleitos.situacao.value_counts().plot(kind='bar', title='Count (target)');\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = eleicoes_train.situacao.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = eleicoes_train[eleicoes_train['situacao'] == 'nao_eleito']\n",
    "df_class_1 = eleicoes_train[eleicoes_train['situacao'] == 'eleito']\n",
    "\n",
    "\n",
    "\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.situacao.value_counts())\n",
    "\n",
    "df_test_under.situacao.value_counts().plot(kind='bar', title='Under Count (situacao)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.situacao.value_counts())\n",
    "\n",
    "df_test_over.situacao.value_counts().plot(kind='bar', title='Over Count (situacao)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Under-sampling: Tomek links\n",
    "\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks(return_indices=True, ratio='majority')\n",
    "X_tl, y_tl, id_tl = tl.fit_sample(eleicoes.loc[:,[\"total_receita\",\"quantidade_doadores\"]], pd.get_dummies(eleitos.situacao).nao_eleito)\n",
    "\n",
    "print('Removed indexes:', id_tl)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_2d_space_logy(X_tl, y_tl, 'Tomek links under-sampling')\n",
    "\n",
    "plt.scatter(\n",
    "    eleicoes[\"total_receita\"],\n",
    "    np.log1p(eleicoes[\"quantidade_doadores\"]),\n",
    "    c=pd.get_dummies(eleitos.situacao).nao_eleito, alpha =0.5\n",
    ")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(X_tl)\n",
    "df['situacao'] = y_tl\n",
    "df.situacao.value_counts().plot(kind='bar', title='Tomek Links Count (situacao)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster Centroids\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "#cc = ClusterCentroids()\n",
    "cc = ClusterCentroids(ratio={1:1000})\n",
    "X_cc, y_cc = cc.fit_sample(eleicoes.loc[:,[\"total_receita\",\"quantidade_doadores\"]], pd.get_dummies(eleitos.situacao).nao_eleito)\n",
    "\n",
    "plot_2d_space_logy(X_cc, y_cc, 'Cluster Centroids under-sampling')\n",
    "\n",
    "plt.scatter(\n",
    "    eleicoes[\"total_receita\"],\n",
    "    np.log1p(eleicoes[\"quantidade_doadores\"]),\n",
    "    c=pd.get_dummies(eleitos.situacao).nao_eleito, alpha =0.5\n",
    ")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(X_cc)\n",
    "df['situacao'] = y_cc\n",
    "df.situacao.value_counts().plot(kind='bar', title='Cluster Centroids Count (situacao)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(ratio='minority')\n",
    "X_sm, y_sm = smote.fit_sample(eleicoes_train.loc[:,[\"total_receita\",\"quantidade_doadores\"]], pd.get_dummies(eleitos.situacao).nao_eleito)\n",
    "\n",
    "plot_2d_space_logy(X_sm, y_sm, 'SMOTE over-sampling')\n",
    "\n",
    "plt.scatter(\n",
    "    eleicoes[\"total_receita\"],\n",
    "    np.log1p(eleicoes[\"quantidade_doadores\"]),\n",
    "    c=pd.get_dummies(eleitos.situacao).nao_eleito, alpha =0.5\n",
    ")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(\n",
    "    eleicoes[\"recursos_de_outros_candidatos.comites\"],\n",
    "    np.log1p(eleicoes[\"recursos_proprios\"]),\n",
    "    c=pd.get_dummies(eleitos.situacao).nao_eleito, alpha =0.5\n",
    ")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(\n",
    "    eleicoes[\"recursos_de_partido_politico\"],\n",
    "    eleicoes[\"recursos_de_pessoas_juridicas\"],\n",
    "    c=pd.get_dummies(eleitos.situacao).nao_eleito, alpha =0.5\n",
    ")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(X_sm)\n",
    "df['situacao'] = y_sm\n",
    "df.situacao.value_counts().plot(kind='bar', title='SMOTE Count (situacao)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_style('darkgrid')\n",
    "#sns.distplot(np.log1p(eleicoes[\"recursos_proprios\"]))\n",
    "\n",
    "\n",
    "orderer = eleitos.situacao.value_counts().index\n",
    "eleicoes2=eleicoes\n",
    "eleicoes2['situacao'] = eleitos.situacao\n",
    "eleicoes2[\"recursos_proprios\"]=np.log1p(eleicoes2[\"recursos_proprios\"])\n",
    "g = sns.FacetGrid(eleicoes2, row=\"situacao\", row_order=orderer,\n",
    "                  aspect=4)\n",
    "g.map(sns.distplot, \"recursos_proprios\", hist=True, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderer = eleitos.situacao.value_counts().index\n",
    "#eleicoes2=eleicoes\n",
    "eleicoes2[\"recursos_de_outros_candidatos.comites\"]=np.log1p(eleicoes2[\"recursos_de_outros_candidatos.comites\"])\n",
    "g = sns.FacetGrid(eleicoes2, row=\"situacao\", row_order=orderer,\n",
    "                  aspect=4)\n",
    "g.map(sns.distplot, \"recursos_de_outros_candidatos.comites\", hist=True, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderer = eleitos.situacao.value_counts().index\n",
    "#eleicoes2=eleicoes\n",
    "eleicoes2[\"recursos_de_partido_politico\"]=eleicoes2[\"recursos_de_partido_politico\"]\n",
    "g = sns.FacetGrid(eleicoes2, row=\"situacao\", row_order=orderer,\n",
    "                  aspect=4)\n",
    "g.map(sns.distplot, \"recursos_de_partido_politico\", hist=True, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "orderer = eleitos.situacao.value_counts().index\n",
    "#eleicoes2=eleicoes\n",
    "eleicoes2[\"recursos_de_pessoas_juridicas\"]=np.log1p(eleicoes2[\"recursos_de_pessoas_juridicas\"])\n",
    "g = sns.FacetGrid(eleicoes2, row=\"situacao\", row_order=orderer,\n",
    "                  aspect=4)\n",
    "g.map(sns.distplot, \"recursos_de_pessoas_juridicas\", hist=True, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#orderer = eleicoes2.partido.value_counts().index\n",
    "\n",
    "#eleicoes2[\"recursos_de_pessoas_fisicas\"]=np.log1p(eleicoes2[\"recursos_de_pessoas_fisicas\"])\n",
    "#g = sns.FacetGrid(eleicoes2.loc[eleicoes['situacao'] == 'eleito'], row=\"partido\", row_order=orderer,\n",
    "#                  aspect=4)\n",
    "#g.map(sns.distplot, \"recursos_de_pessoas_fisicas\", hist=True, rug=True);\n",
    "\n",
    "orderer = eleitos.situacao.value_counts().index\n",
    "#eleicoes2=eleicoes\n",
    "eleicoes2[\"recursos_de_pessoas_fisicas\"]=np.log1p(eleicoes2[\"recursos_de_pessoas_fisicas\"])\n",
    "g = sns.FacetGrid(eleicoes2, row=\"situacao\", row_order=orderer,\n",
    "                  aspect=4)\n",
    "g.map(sns.distplot, \"recursos_de_pessoas_fisicas\", hist=True, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orderer = eleitos.situacao.value_counts().index\n",
    "#eleicoes2=eleicoes\n",
    "eleicoes2[\"quantidade_doadores\"]=np.log1p(eleicoes2[\"quantidade_doadores\"])\n",
    "g = sns.FacetGrid(eleicoes2, row=\"situacao\", row_order=orderer,\n",
    "                  aspect=4)\n",
    "g.map(sns.distplot, \"quantidade_doadores\", hist=True, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'eleito'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-273-0cb6387f73b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_smt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_smt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meleicoes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ocupacao_DEPUTADO'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'recursos_proprios'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'recursos_de_pessoas_fisicas'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'recursos_de_pessoas_juridicas'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'region_SE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'region_NE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'region_NO'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'region_SU'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'direction_R'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'direction_C'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meleicoes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meleito\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplot_2d_space_logy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_smt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_smt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SMOTE + Tomek links'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4370\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4371\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4372\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'eleito'"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(ratio='auto')\n",
    "X_smt, y_smt = smt.fit_sample(eleicoes.loc[:,['ocupacao_DEPUTADO','recursos_proprios','recursos_de_pessoas_fisicas','recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']], eleicoes.eleito)\n",
    "\n",
    "plot_2d_space_logy(X_smt, y_smt, 'SMOTE + Tomek links')\n",
    "\n",
    "plt.scatter(\n",
    "    eleicoes[\"total_receita\"],\n",
    "    np.log1p(eleicoes[\"quantidade_doadores\"]),\n",
    "    c=pd.get_dummies(eleitos.situacao).nao_eleito, alpha =0.5\n",
    ")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(X_smt)\n",
    "df['situacao'] = y_smt\n",
    "df.situacao.value_counts().plot(kind='bar', title='SMOTE + Tomek links Count (situacao)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "#import math\n",
    "def Stacking(model,train,y,test,n_fold):\n",
    "    folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
    "    #test_pred=np.empty((test.shape[0],1),float)\n",
    "    test_pred=None\n",
    "    train_pred=np.empty((0,1),float)\n",
    "    for train_indices,val_indices in folds.split(train,y.values):\n",
    "        x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n",
    "        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
    "\n",
    "        model.fit(X=x_train,y=y_train)\n",
    "        train_pred=np.append(train_pred,model.predict(x_val))\n",
    "        #test_pred=np.append(test_pred,model.predict(test))\n",
    "        if test_pred is None:\n",
    "            test_pred=pd.DataFrame(model.predict(test))\n",
    "        else:\n",
    "            test_pred=pd.concat([test_pred, pd.DataFrame(model.predict(test))], axis=1)\n",
    "    #return test_pred.reshape(-1,1),train_pred\n",
    "    return test_pred,train_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model,x,y):#x é dataframe e y é list\n",
    "    #rmse= np.sqrt(-cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv = 5, scoring='recall'))\n",
    "    rmse= np.sqrt(-cross_val_score(model, x, y, cv = 5, scoring='precision'))\n",
    "    return(rmse)\n",
    "\n",
    "#def rmse_cv_final(model):\n",
    "#    rmse= np.sqrt(-cross_val_score(model, x_teste_final, y_teste_final.votos, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "#    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AC', 'AL', 'AM', 'AP', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MG',\n",
       "       'MS', 'MT', 'PA', 'PB', 'PE', 'PI', 'PR', 'RJ', 'RN', 'RO', 'RR',\n",
       "       'RS', 'SC', 'SE', 'SP', 'TO'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(eleicoes_val.loc[:,['uf']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleicoes = pd.get_dummies(eleicoes, \n",
    "                          prefix=['situacao'], \n",
    "                          columns=['situacao'])\n",
    "\n",
    "eleicoes_val = pd.get_dummies(eleicoes_val, \n",
    "                          prefix=['situacao'], \n",
    "                          columns=['situacao'])\n",
    "\n",
    "eleicoes_val2 = pd.get_dummies(eleicoes_val2, \n",
    "                          prefix=['situacao'], \n",
    "                          columns=['situacao'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eleicoes = eleicoes.reset_index()\n",
    "eleicoes_val = eleicoes_val.reset_index()\n",
    "eleicoes_val2 = eleicoes_val2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan]\n",
      "0.8825261780104712\n",
      "0.8762571053782248\n",
      "0.8911803422553751\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model1 = tree.DecisionTreeClassifier(criterion = \"entropy\", splitter = 'random', max_leaf_nodes = 12, min_samples_leaf = 15, max_depth= 10)\n",
    "#model1.fit(eleicoes.loc[:,['recursos_de_pessoas_juridicas']], eleicoes.loc[:,['situacao_eleito']])\n",
    "model1.fit(eleicoes.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']], eleicoes.loc[:,['situacao_eleito']])\n",
    "#val_pred1=model1.predict(eleicoes_val.loc[:,['recursos_de_pessoas_juridicas']])\n",
    "val_pred1=model1.predict(eleicoes_val.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']])\n",
    "#test_pred1=model1.predict(eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas']])\n",
    "test_pred1=model1.predict(eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']])\n",
    "val_pred1=pd.DataFrame(val_pred1)\n",
    "test_pred1=pd.DataFrame(test_pred1)\n",
    "\n",
    "print(rmse_cv(model1,eleicoes.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']],eleicoes.loc[:,['situacao_eleito']]))\n",
    "\n",
    "print(model1.score(eleicoes.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']],eleicoes.loc[:,['situacao_eleito']]))\n",
    "print(model1.score(eleicoes_val.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']],eleicoes_val.loc[:,['situacao_eleito']]))\n",
    "print(model1.score(eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']],eleicoes_val2.loc[:,['situacao_eleito']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31726401 0.320694   0.29277002 0.31448545 0.32139804]\n",
      "0.8992146596858639\n",
      "0.8889374726716223\n",
      "0.9078543220710839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model1 = GradientBoostingClassifier(learning_rate=0.01,random_state=1)\n",
    "#model1.fit(eleicoes.loc[:,['recursos_de_pessoas_juridicas']], eleicoes.loc[:,['situacao_eleito']])\n",
    "model1.fit(eleicoes.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']], eleicoes.loc[:,['situacao_eleito']])\n",
    "#val_pred1=model1.predict(eleicoes_val.loc[:,['recursos_de_pessoas_juridicas']])\n",
    "val_pred1=model1.predict(eleicoes_val.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']])\n",
    "#test_pred1=model1.predict(eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas']])\n",
    "test_pred1=model1.predict(eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']])\n",
    "val_pred1=pd.DataFrame(val_pred1)\n",
    "test_pred1=pd.DataFrame(test_pred1)\n",
    "\n",
    "print(rmse_cv(model1,eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']],eleicoes_val2.loc[:,['situacao_eleito']]))\n",
    "\n",
    "print(model1.score(eleicoes.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']],eleicoes.loc[:,['situacao_eleito']]))\n",
    "print(model1.score(eleicoes_val.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']],eleicoes_val.loc[:,['situacao_eleito']]))\n",
    "print(model1.score(eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']],eleicoes_val2.loc[:,['situacao_eleito']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9132853403141361\n",
      "0.9077393965894185\n",
      "0.912681000438789\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model1 = AdaBoostClassifier(random_state=1)\n",
    "#model1.fit(eleicoes.loc[:,['recursos_de_pessoas_juridicas']], eleicoes.loc[:,['situacao_eleito']])\n",
    "model1.fit(eleicoes.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']], eleicoes.loc[:,['situacao_eleito']])\n",
    "#val_pred1=model1.predict(eleicoes_val.loc[:,['recursos_de_pessoas_juridicas']])\n",
    "val_pred1=model1.predict(eleicoes_val.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']])\n",
    "#test_pred1=model1.predict(eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas']])\n",
    "test_pred1=model1.predict(eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']])\n",
    "val_pred1=pd.DataFrame(val_pred1)\n",
    "test_pred1=pd.DataFrame(test_pred1)\n",
    "print(model1.score(eleicoes.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']],eleicoes.loc[:,['situacao_eleito']]))\n",
    "print(model1.score(eleicoes_val.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']],eleicoes_val.loc[:,['situacao_eleito']]))\n",
    "print(model1.score(eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas','region_SE','region_NE','region_NO','region_SU','direction_R','direction_C']],eleicoes_val2.loc[:,['situacao_eleito']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.863975427819219"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model2 = KNeighborsClassifier()\n",
    "model2.fit(eleicoes.loc[:,['ocupacao_DEPUTADO','recursos_proprios']], eleicoes.loc[:,['situacao_eleito']])\n",
    "val_pred2=model2.predict(eleicoes_val.loc[:,['ocupacao_DEPUTADO','recursos_proprios']])\n",
    "test_pred2=model2.predict(eleicoes_val2.loc[:,['ocupacao_DEPUTADO','recursos_proprios']])\n",
    "val_pred2=pd.DataFrame(val_pred2)\n",
    "test_pred2=pd.DataFrame(test_pred2)\n",
    "model2.score(eleicoes_val2.loc[:,['ocupacao_DEPUTADO','recursos_proprios']],eleicoes_val2.loc[:,['situacao_eleito']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9136125654450262\n",
      "0.9042413642326191\n",
      "0.8968845985081176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model3 = AdaBoostClassifier(random_state=1)\n",
    "model3.fit(eleicoes.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_fisicas','region_SU','region_SE','region_NE','region_NO','direction_R','direction_C']], eleicoes.loc[:,['situacao_eleito']])\n",
    "val_pred3=model3.predict(eleicoes_val.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_fisicas','region_SU','region_SE','region_NE','region_NO','direction_R','direction_C']])\n",
    "test_pred3=model3.predict(eleicoes_val2.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_fisicas','region_SU','region_SE','region_NE','region_NO','direction_R','direction_C']])\n",
    "val_pred3=pd.DataFrame(val_pred3)\n",
    "test_pred3=pd.DataFrame(test_pred3)\n",
    "print(model3.score(eleicoes.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_fisicas','region_SU','region_SE','region_NE','region_NO','direction_R','direction_C']],eleicoes.loc[:,['situacao_eleito']]))\n",
    "print(model3.score(eleicoes_val.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_fisicas','region_SU','region_SE','region_NE','region_NO','direction_R','direction_C']],eleicoes_val.loc[:,['situacao_eleito']]))\n",
    "print(model3.score(eleicoes_val2.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_fisicas','region_SU','region_SE','region_NE','region_NO','direction_R','direction_C']],eleicoes_val2.loc[:,['situacao_eleito']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9164844774814167\n",
      "0.9157525230364195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#df_val=pd.concat([eleicoes_val.loc[:,['recursos_de_pessoas_juridicas','recursos_proprios']], val_pred1,val_pred2],axis=1)\n",
    "df_val=pd.concat([eleicoes_val.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_juridicas','recursos_de_pessoas_fisicas','direction_R','direction_C']], val_pred1,val_pred2,val_pred3],axis=1)\n",
    "#df_test=pd.concat([eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas','recursos_proprios']], test_pred1,test_pred2],axis=1)\n",
    "df_test=pd.concat([eleicoes_val2.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_juridicas','recursos_de_pessoas_fisicas','direction_R','direction_C']], test_pred1,test_pred2,test_pred3],axis=1)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(df_val,eleicoes_val.loc[:,['situacao_eleito']])\n",
    "print(model.score(df_val,eleicoes_val.loc[:,['situacao_eleito']]))\n",
    "print(model.score(df_test,eleicoes_val2.loc[:,['situacao_eleito']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.929602098819414\n",
      "0.9144361562088635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#df_val=pd.concat([eleicoes_val.loc[:,['recursos_de_pessoas_juridicas','recursos_proprios']], val_pred1,val_pred2],axis=1)\n",
    "df_val=pd.concat([eleicoes_val.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_juridicas','recursos_de_pessoas_fisicas','direction_R','direction_C']], val_pred1,val_pred2,val_pred3],axis=1)\n",
    "#df_test=pd.concat([eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas','recursos_proprios']], test_pred1,test_pred2],axis=1)\n",
    "df_test=pd.concat([eleicoes_val2.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_juridicas','recursos_de_pessoas_fisicas','direction_R','direction_C']], test_pred1,test_pred2,test_pred3],axis=1)\n",
    "\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion=\"gini\",\n",
    "                               max_depth=15, max_features=\"auto\", max_leaf_nodes=10,\n",
    "                               min_samples_leaf=3,\n",
    "                               min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
    "                               n_estimators=10, n_jobs=1, oob_score=False, random_state=1,\n",
    "                               verbose=0, warm_start=False)\n",
    "model.fit(df_val,eleicoes_val.loc[:,['situacao_eleito']])\n",
    "print(model.score(df_val,eleicoes_val.loc[:,['situacao_eleito']]))\n",
    "print(model.score(df_test,eleicoes_val2.loc[:,['situacao_eleito']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-272-0987a004e195>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshrinking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     tol=0.001, verbose=False)\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meleicoes_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'situacao_eleito'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meleicoes_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'situacao_eleito'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meleicoes_val2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'situacao_eleito'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\svm\\libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not str"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#df_val=pd.concat([eleicoes_val.loc[:,['recursos_de_pessoas_juridicas','recursos_proprios']], val_pred1,val_pred2],axis=1)\n",
    "df_val=pd.concat([eleicoes_val.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_juridicas','recursos_de_pessoas_fisicas','direction_R','direction_C']], val_pred1,val_pred2,val_pred3],axis=1)\n",
    "#df_test=pd.concat([eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas','recursos_proprios']], test_pred1,test_pred2],axis=1)\n",
    "df_test=pd.concat([eleicoes_val2.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_juridicas','recursos_de_pessoas_fisicas','direction_R','direction_C']], test_pred1,test_pred2,test_pred3],axis=1)\n",
    "\n",
    "model = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "model.fit(df_val,eleicoes_val.loc[:,['situacao_eleito']])\n",
    "print(model.score(df_val,eleicoes_val.loc[:,['situacao_eleito']]))\n",
    "print(model.score(df_test,eleicoes_val2.loc[:,['situacao_eleito']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tclem\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9182334936598163\n",
      "0.9148749451513822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#df_val=pd.concat([eleicoes_val.loc[:,['recursos_de_pessoas_juridicas','recursos_proprios']], val_pred1,val_pred2],axis=1)\n",
    "df_val=pd.concat([eleicoes_val.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_juridicas','recursos_de_pessoas_fisicas','direction_R','direction_C']], val_pred1,val_pred2,val_pred3],axis=1)\n",
    "#df_test=pd.concat([eleicoes_val2.loc[:,['recursos_de_pessoas_juridicas','recursos_proprios']], test_pred1,test_pred2],axis=1)\n",
    "df_test=pd.concat([eleicoes_val2.loc[:,['ocupacao_DEPUTADO','recursos_de_pessoas_juridicas','recursos_de_pessoas_fisicas','direction_R','direction_C']], test_pred1,test_pred2,test_pred3],axis=1)\n",
    "\n",
    "model = GradientBoostingClassifier(learning_rate=0.01,random_state=1)\n",
    "model.fit(df_val,eleicoes_val.loc[:,['situacao_eleito']])\n",
    "print(model.score(df_val,eleicoes_val.loc[:,['situacao_eleito']]))\n",
    "print(model.score(df_test,eleicoes_val2.loc[:,['situacao_eleito']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que dividimos os dados em dois seguimentos: as eleições de 2006 e 2010 foram separadas para validação e treinamento. Já a eleição de 2014 será nossa base de testes. Para o a validação, dividimos a base de treino aleatoriamente entre treino e validação (75% para treino e 25% para validação). Após a fase de validação, identificados os parâmetros mais adequados, retreinamos nosso modelo com a base de treinamento completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eleicoes_2014.head(10)\n",
    "#eleicoes_2006 = eleicoes[eleicoes['ano'] == 2006]\n",
    "#treino = eleicoes_2006.loc[:,[\n",
    "#       'uf', 'quantidade_doacoes', 'total_receita', 'partido', 'quantidade_doadores', \n",
    "#       'recursos_de_outros_candidatos/comites',\n",
    "#       'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "#       'recursos_proprios', 'quantidade_despesas', 'quantidade_fornecedores',\n",
    "#       'total_despesa', 'cargo', 'sexo', 'grau',\n",
    "#       'estado_civil', 'ocupacao', 'votos'\n",
    "#    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#eleicoes.loc[eleicoes['ano'] == 2014].head(10)\n",
    "#eleicoes_2010 = eleicoes[eleicoes['ano'] == 2010]\n",
    "#validacao = eleicoes_2010.loc[:,[\n",
    "#       'uf', 'quantidade_doacoes', 'total_receita', 'partido', 'quantidade_doadores', \n",
    "#       'recursos_de_outros_candidatos/comites',\n",
    "#       'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "#       'recursos_proprios', 'quantidade_despesas', 'quantidade_fornecedores',\n",
    "#       'total_despesa', 'cargo', 'sexo', 'grau',\n",
    "#       'estado_civil', 'ocupacao', 'votos'\n",
    "#    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eleicoes_2006_a_2010 = eleicoes[eleicoes['ano'] == 2010 || eleicoes['ano'] == 2006]\n",
    "#treino_final = eleicoes_2006_a_2010.loc[:,[\n",
    "#       'uf', 'quantidade_doacoes', 'total_receita', 'partido', 'quantidade_doadores', \n",
    "#       'recursos_de_outros_candidatos/comites',\n",
    "#       'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "#       'recursos_proprios', 'quantidade_despesas', 'quantidade_fornecedores',\n",
    "#       'total_despesa', 'cargo', 'sexo', 'grau',\n",
    "#       'estado_civil', 'ocupacao', 'votos'\n",
    "#    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#eleicoes_2014 = eleicoes[eleicoes['ano'] == 2014]\n",
    "#teste_final = eleicoes_2014.loc[:,[\n",
    "#       'uf', 'quantidade_doacoes', 'total_receita', 'partido', 'quantidade_doadores', \n",
    "#       'recursos_de_outros_candidatos/comites',\n",
    "#       'recursos_de_pessoas_fisicas', 'recursos_de_pessoas_juridicas',\n",
    "#       'recursos_proprios', 'quantidade_despesas', 'quantidade_fornecedores',\n",
    "#       'total_despesa', 'cargo', 'sexo', 'grau',\n",
    "#       'estado_civil', 'ocupacao', 'votos'\n",
    "#    ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos agora as colunas de dados de treino e teste finais. Os atributos categóricos foram convertidos em numéricos utilizando uma estratégia de dumming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_treino_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenando os preditores dos datasets de treino e teste\n",
    "#all_data_treino = pd.concat((x_treino.loc[:,'uf':'ocupacao'],\n",
    "#                      x_validacao.loc[:,'uf':'ocupacao']))\n",
    "\n",
    "#all_data_final = pd.concat((x_treino_final.loc[:,'uf':'ocupacao'],\n",
    "#                      x_teste_final.loc[:,'uf':'ocupacao']))\n",
    "x_teste_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento\n",
    "\n",
    "Aqui analisaremos os dados de forma mais ampla, fazendo modificações e preenchendo lacunas quando necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando quais transformação normaliza os dados\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 12.0)\n",
    "\n",
    "votos = pd.DataFrame({\"Votos\":y_treino_final[\"votos\"], \"log(Votos)\":np.log(y_treino_final[\"votos\"]), \\\n",
    "                       \"sqrt(Votos)\":np.sqrt(y_treino_final[\"votos\"]),\"square(Votos)\":np.square(y_treino_final[\"votos\"])})\n",
    "votos.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando a disbribução normal como a mais adequada para qualquer tratamento restatístico, faremos a transformação dos dados usando a função logarítmica. Tal função, como é possível observar nos gráficos acima, é a que mais aproxima o atributo `Votos` da distribuição normal.\n",
    "\n",
    "Vale frizar que feremos esta transformação apenas em validação e treino, afim de identificar os melhores parâmetros. Na fase de testes usaremos a distribuição original para chegarmos a resultados mais inteligíveis. Em função disto, os RMSEs na validação e nos testes serão significativamente diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log transform the target:\n",
    "y_treino = np.log1p(y_treino)#treino[\"votos\"] = np.log1p(treino[\"votos\"])\n",
    "y_validacao = np.log1p(y_validacao)#validacao[\"votos\"] = np.log1p(validacao[\"votos\"])\n",
    "####y_treino_final = np.log1p(y_treino_final)#treino_final[\"votos\"] = np.log1p(treino_final[\"votos\"])\n",
    "####y_teste_final = np.log1p(y_teste_final)#teste_final[\"votos\"] = np.log1p(teste_final[\"votos\"])\n",
    "#eleicoes[\"votos\"] = np.log1p(eleicoes[\"votos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#selecionando atributos numéricos\n",
    "numeric_feats = eleicoes.dtypes[eleicoes.dtypes != \"object\"].index\n",
    "\n",
    "#normalizando atributos numéricos exceto ano\n",
    "x_treino[numeric_feats[1 :]] = np.log1p(x_treino[numeric_feats[1:]])\n",
    "x_validacao[numeric_feats[1 :]] = np.log1p(x_validacao[numeric_feats[1:]])\n",
    "####x_treino_final[numeric_feats[1 :]] = np.log1p(x_treino_final[numeric_feats[1:]])\n",
    "####x_teste_final[numeric_feats[1 :]] = np.log1p(x_teste_final[numeric_feats[1:]])\n",
    "\n",
    "\n",
    "\n",
    "#log transform skewed numeric features:\n",
    "#numeric_feats = all_data_treino.dtypes[all_data_treino.dtypes != \"object\"].index\n",
    "\n",
    "#skewed_feats = all_data_treino[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "##skewed_feats = x_validacao[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "#skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "#skewed_feats = skewed_feats.index\n",
    "\n",
    "#all_data_treino[skewed_feats] = np.log1p(all_data_treino[skewed_feats])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#numeric_feats = all_data_final.dtypes[all_data_final.dtypes != \"object\"].index\n",
    "\n",
    "#skewed_feats = all_data_final[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "##skewed_feats = x_teste_final[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "#skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "#skewed_feats = skewed_feats.index\n",
    "\n",
    "#all_data_final[skewed_feats] = np.log1p(all_data_final[skewed_feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que os dados de teste e treino finais foram mantidos inalterados. Utilizaremos a função logarítmica apenas para encontrar os parâmetros de cana modelo (apenas na fase de validação)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling NA's with the mean of the column:\n",
    "#all_data_treino = all_data_treino.fillna(all_data_treino.mean())\n",
    "#all_data_final = all_data_final.fillna(all_data_final.mean())\n",
    "x_treino = x_treino.fillna(x_treino.mean())\n",
    "x_validacao = x_validacao.fillna(x_validacao.mean())\n",
    "x_treino_final = x_treino_final.fillna(x_treino_final.mean())\n",
    "x_teste_final = x_teste_final.fillna(x_teste_final.mean())\n",
    "\n",
    "y_treino = y_treino.fillna(y_treino.mean())\n",
    "y_validacao = y_validacao.fillna(y_validacao.mean())\n",
    "y_treino_final = y_treino_final.fillna(y_treino_final.mean())\n",
    "y_teste_final = y_teste_final.fillna(y_teste_final.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As lacunas vazias nos dados foram preenchidas com a média de cada coluna. Veja abaicho que já podemos observar os dummies para os atributos categóricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste_final.head(10)\n",
    "\n",
    "#creating matrices for sklearn:\n",
    "#X_treino = all_data_treino[:treino.shape[0]]\n",
    "#X_validacao = all_data_treino[treino.shape[0]:]\n",
    "#y_treino = treino.votos\n",
    "#y_validacao = validacao.votos\n",
    "\n",
    "#creating matrices for sklearn:\n",
    "#X_treino_final = all_data_final[:treino_final.shape[0]]\n",
    "#X_teste_final = all_data_final[treino_final.shape[0]:]\n",
    "#y_treino_final = treino_final.votos\n",
    "#y_teste_final = teste_final.votos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos\n",
    "\n",
    "Descreveremos agora cada um de quatro modelos de predição distintos: regressão simples, com regularização Ridge, com regularização Lasso, K-NN, além de um modelo não visto em sala de aula chamado Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, x_validacao, y_validacao.votos, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n",
    "def rmse_cv_final(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, x_teste_final, y_teste_final.votos, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sem regularização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validacao.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=LinearRegression()\n",
    "lm.fit(x_treino,y_treino)\n",
    "print(\"Intercept: \" + str(lm.intercept_[0]))\n",
    "print(\"RMSE: \" + str(rmse_cv(lm).mean()))\n",
    "\n",
    "coef_df = pd.DataFrame(lm.coef_[0],x_treino.columns,columns=['Coefficient'])\n",
    "coef_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE de mais de 22 mlhões de votos. Péssimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com regularização Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50]\n",
    "cv_ridge = [rmse_cv(Ridge(alpha = alpha).fit(x_treino,y_treino)).mean() for alpha in alphas]\n",
    "cv_ridge = pd.Series(cv_ridge, index = alphas)\n",
    "cv_ridge.plot(title = \"Validation - Just Do It\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"rmse\")\n",
    "\n",
    "print(\"Mínmo RMSE: \" + str(cv_ridge.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE de 0.968239, aceitável.\n",
    "\n",
    "Seguiremos agora utilizando o melhor alpha para o modelo Ridge (alpha = 5), com os dados de treino completos e predizendo os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_ridge = Ridge(alpha = 5)\n",
    "modelo_ridge.fit(x_treino_final,y_treino_final)\n",
    "print(\"Intercept: \" + str(modelo_ridge.intercept_[0]))\n",
    "print(\"RMSE: \" + str(rmse_cv_final(modelo_ridge).mean()))\n",
    "coef_ridge = pd.DataFrame(modelo_ridge.coef_[0],x_treino.columns,columns=['Coefficient'])\n",
    "coef_ridge.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos um RMSE real (de teste) de 33.981,52 votos. Perceba que, como já havíamos mencionado, o RMSE de teste (real) é bem diferentes do RMSE de validação. Isto ocorre pois realizamos a transformação logarítmica nas bases de validação e treino para validação, e não a fizemos nas bases de treino final e testes. Vale lembrar também que na prática calcular este RMSE de teste raramente é possível.\n",
    "\n",
    "Comparamos agora, com base nos resíduos, a capacidade de predição do modelo já treinado para os próprios dados de treino e para os dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the residuals as well:\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "preds = pd.DataFrame({\"preds\":modelo_ridge.predict(x_treino_final)[:,0], \"true\":y_treino_final.votos})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\", title = \"Dados de treino\")\n",
    "\n",
    "#let's look at the residuals as well:\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "preds = pd.DataFrame({\"preds\":modelo_ridge.predict(x_teste_final)[:,0], \"true\":y_teste_final.votos})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\",title = \"Dados de teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico de resíduos parece um pouco enviezado, mas tanto validação quanto teste apresentam uma disperssão parecida, o que descarta overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com regularização Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"::::Validação:::::\")\n",
    "\n",
    "alphas = np.arange(0.0001,0.005,0.0001).tolist()\n",
    "\n",
    "rmse_cv_lasso = [rmse_cv(Lasso(alpha = alpha, max_iter=8000).fit(x_treino,y_treino)).mean() \n",
    "            for alpha in alphas]\n",
    "\n",
    "#print(\"RMSE validação: \" + str(rmse_cv_lasso.mean()))\n",
    "#print(\"Mínmo RMSE: \" + str(rmse_cv_lasso.min()))\n",
    "\n",
    "rmse_cv_lasso = pd.Series(rmse_cv_lasso, index = alphas)\n",
    "rmse_cv_lasso.plot(title = \"Validation - Just Do It\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"rmse\")\n",
    "\n",
    "rmse_cv_lasso.min()\n",
    "\n",
    "#modelo_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005], max_iter=10000).fit(x_treino, y_treino.votos)\n",
    "#rmse_cv_lasso = rmse_cv(modelo_lasso)\n",
    "#rmse_lasso=rmse_cv_lasso.mean()\n",
    "#print(\"Intercept validação: \" + str(modelo_lasso.intercept_))\n",
    "#print(\"RMSE validação: \" + str(rmse_lasso))\n",
    "#print(\"Mínmo RMSE: \" + str(rmse_cv_lasso.min()))\n",
    "\n",
    "#coef = pd.DataFrame(modelo_lasso.coef_, index = x_treino.columns, columns=['Coefficient']) #coeficientes\n",
    "#coef.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE de treino de 0.97145, maior que o da regressão com regularização Ridge, mas vamos proseguir mesmo assim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"::::Teste:::::\")\n",
    "\n",
    "#alphas = np.arange(0.0001,0.005,0.0001).tolist()\n",
    "\n",
    "modelo_lasso_final = Lasso(alpha = 0.0016, max_iter=8000).fit(x_treino_final,y_treino_final)\n",
    "#rmse_cv_lasso_final = rmse_cv_final(Lasso(alpha = 0.0016, max_iter=8000))\n",
    "rmse_cv_lasso_final = rmse_cv_final(modelo_lasso_final)\n",
    "\n",
    "#modelo_lasso_final = LassoCV(alphas = [1, 0.1, 0.001, 0.0005], max_iter=10000).fit(x_treino_final, y_treino_final.votos)\n",
    "#rmse_cv_lasso_final = rmse_cv_final(modelo_lasso_final)\n",
    "rmse_lasso_final=rmse_cv_lasso_final.mean()\n",
    "print(\"Intercept validação: \" + str(modelo_lasso_final.intercept_))\n",
    "print(\"RMSE validação: \" + str(rmse_lasso_final))\n",
    "#print(\"Mínmo RMSE: \" + str(rmse_cv_lasso_final.min()))\n",
    "coef = pd.DataFrame(modelo_lasso_final.coef_, index = x_treino_final.columns, columns=['Coefficient']) #coeficientes\n",
    "coef.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE de mais de 34.000 votos. Pior que o da regressão Ridge, como já prevíamos. A título de informação, veja abaixo quantos coeficientes foram removidos e mantidos durante a regressão Lasso (remover coeficientes pouco úteis é uma peculiaridade deste modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coef = pd.Series(modelo_lasso.coef_, index = x_treino.columns)\n",
    "coef_final = pd.Series(modelo_lasso_final.coef_, index = x_treino_final.columns)\n",
    "\n",
    "#print(\"Train: Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "\n",
    "print(\"Final train: Lasso picked \" + str(sum(coef_final != 0)) + \" variables and eliminated the other \" +  str(sum(coef_final == 0)) + \" variables\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos agora observar graficamente quais são os coeficientes são mais importantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imp_coef = pd.concat([coef.sort_values().head(10),\n",
    "#                     coef.sort_values().tail(10)])\n",
    "\n",
    "imp_coef_final = pd.concat([coef_final.sort_values().head(10),\n",
    "                     coef_final.sort_values().tail(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "#imp_coef.plot(kind = \"barh\")\n",
    "#plt.title(\"Coefficients in the Lasso Model :::Treino:::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef_final.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Lasso Model :::Teste:::\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atributos dummies associados a um único candidado como `ocupacao_TÉCNICO EM EDIFICAÇÕES` ou `ocupacao_ATOR E DIRETOR DE ESPETÁCULOS PÚBLICOS` podem ganhar muita importância em função de sua votação particular. Os atributos que mais interferem no resultado são: `grau_de_instrucao`, `sigla_uf` e `ocupacao`, independente do processo de dumming. O atributo `sigla_uf`, de um modo geral parece ser bem relevante, indo de interferência mais negativa `sigla_uf_PR` para muito positiva `sigla_uf_CE`. Atributos aparentemente relevantes como `total_despesa` foram removidos. \n",
    "\n",
    "Veja abaixo que a distribuição de resíduos parece semelhante entre validação e este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#let's look at the residuals as well:\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "#preds = pd.DataFrame({\"preds\":modelo_lasso.predict(X_validacao), \"true\":y_validacao})\n",
    "preds = pd.DataFrame({\"preds\":modelo_lasso_final.predict(x_treino_final), \"true\":y_treino_final.votos})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "plt.title(\":::Treino:::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#let's look at the residuals as well:\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "preds = pd.DataFrame({\"preds\":modelo_lasso_final.predict(x_teste_final), \"true\":y_teste_final.votos})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "plt.title(\":::Teste:::\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico de resíduos parece oscilar em torno de 250.000 e -250.000 votos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Não paramétrica K-NN\n",
    "\n",
    "Aqui trataremos da regressão ligada aos vizinhos mais próximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "n_neighbors = [1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "cv_knn = [rmse_cv(KNeighborsRegressor(n_neighbors = n_neighbor).fit(x_treino,y_treino)).mean() for n_neighbor in n_neighbors]\n",
    "cv_knn = pd.Series(cv_knn, index = n_neighbors)\n",
    "cv_knn.plot(title = \"Validation - Just Do It\")\n",
    "plt.xlabel(\"neighbors\")\n",
    "plt.ylabel(\"rmse\")\n",
    "cv_knn.min()\n",
    "\n",
    "#modelo_knn.predict(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE de 0.98, ruim, mas seguiremos em frente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_knn = KNeighborsRegressor(n_neighbors = 20)\n",
    "modelo_knn.fit(x_treino,y_treino)\n",
    "\n",
    "#let's look at the residuals as well:\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "preds = pd.DataFrame({\"preds\":modelo_knn.predict(x_validacao)[:,0], \"true\":y_validacao.votos})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "plt.title(\":::Treino:::\")\n",
    "\n",
    "\n",
    "#preds = pd.DataFrame({\"preds\":modelo_lasso_final.predict(x_teste_final), \"true\":y_teste_final.votos})\n",
    "#preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "#preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "#plt.title(\":::Teste:::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv_final(modelo_knn).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE real de menos de 32.000 votos, o menor até agora, mesmo com um RMSE de validação não tão bom. Seguiremos para os resíduos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_knn = KNeighborsRegressor(n_neighbors = 20)\n",
    "modelo_knn.fit(x_treino_final,y_treino_final)\n",
    "\n",
    "#let's look at the residuals as well:\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "preds = pd.DataFrame({\"preds\":modelo_knn.predict(x_teste_final)[:,0], \"true\":y_teste_final.votos})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "plt.title(\":::Teste:::\")\n",
    "\n",
    "\n",
    "#preds = pd.DataFrame({\"preds\":modelo_lasso_final.predict(x_teste_final), \"true\":y_teste_final.votos})\n",
    "#preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "#preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")\n",
    "#plt.title(\":::Teste:::\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanto aos resíduos, nada muito diferente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Trataremos aqui de Random Forest, único modelo deste relatório não tratado em sala de aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 400, 700, 900, 1000, 1200, 1400, 2000]\n",
    "cv_rfr = [rmse_cv(RandomForestRegressor(max_depth=10, random_state=0, n_estimators = n_estimator).fit(x_treino,y_treino.votos)).mean() for n_estimator in n_estimators]\n",
    "cv_rfr = pd.Series(cv_rfr, index = n_estimators)\n",
    "cv_rfr.plot(title = \"Validation - Just Do It\")\n",
    "plt.xlabel(\"estimators\")\n",
    "plt.ylabel(\"rmse\")\n",
    "cv_rfr.min()\n",
    "\n",
    "#rfr = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "#rfr.fit(X, y)\n",
    "#print([cv.feature_importances_ for cv in cv_rfr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE de validação de 0.955, melhor até agora. Seguremos para os resíduos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=10, random_state=0, n_estimators=900)\n",
    "rfr.fit(x_treino,y_treino)\n",
    "#let's look at the residuals as well:\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "preds = pd.DataFrame({\"preds\":rfr.predict(x_validacao), \"true\":y_validacao.votos})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=10, random_state=0, n_estimators=900)\n",
    "rfr.fit(x_treino_final,y_treino_final)\n",
    "#let's look at the residuals as well:\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "preds = pd.DataFrame({\"preds\":rfr.predict(x_teste_final), \"true\":y_teste_final.votos})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note acima uma distrubuição menos enviezada, porém ainda em um espectro muito similar ao dos demais modelos.\n",
    "\n",
    "Veja abaixo que chegamos a um RMSE de 33.535. Com isto concluímos que o modelo K-NN, com RMSE de 31.941 prevê melhor os resultados para a eleição de 2014 com base em 2010 e 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv_final(rfr).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumarização\n",
    "\n",
    "Como pudemos observar, os melhores resultados são alcançados utilizando o modelo de regressão K-NN, tendo um RMSE no teste de aproximadamente 31.941 votos e apresentando uma disperssão no gráfico de resíduos menos concisa que a do modelo Random Forest, porém ambas enviezadas. É importante frizar que, embora a regressão K-NN seja superior em resultados, mesmo esta ainda apresenta um poder de previsão pouco útil na prática.\n",
    "\n",
    "Como os resultados dos modelos foram bem próximos, é difícil dar um diagnóstico preciso a respeito do porquê um foi melhor que o outro. O úico modelo com desempenho que distoa dos demais é a regressão simples, pois não aplica nenhuma estratégia de ajuste e, com isto, leva grande desvantagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
